import json
import re
import string # êµ¬ë‘ì  ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€

# --- vqa_eval.pyì˜ í—¬í¼ í•¨ìˆ˜ ë° ìƒìˆ˜ ---
# ì œê³µëœ vqa_eval.py ìŠ¤ë‹ˆí«ì—ì„œ ì¶”ì¶œ ë° ì ìš©

MANUAL_MAP = {
    'none': '0',
    'zero': '0',
    'one': '1',
    'two': '2',
    'three': '3',
    'four': '4',
    'five': '5',
    'six': '6',
    'seven': '7',
    'eight': '8',
    'nine': '9',
    'ten': '10',
}

CONTRACTIONS = {
    'aint': "ain't", 'arent': "aren't", 'cant': "can't", 'couldve': "could've",
    'couldnt': "couldn't", "couldn'tve": "couldn't've", "couldnt've": "couldn't've",
    'didnt': "didn't", 'doesnt': "doesn't", 'dont': "don't", 'hadnt': "hadn't",
    "hadnt've": "hadn't've", "hadn'tve": "hadn't've", 'hasnt': "hasn't",
    'havent': "haven't", 'hed': "he'd", "hed've": "he'd've", "he'dve": "he'd've",
    'hes': "he's", 'howd': "how'd", 'howll': "how'll", 'hows': "how's",
    "Id've": "I'd've", "I'dve": "I'd've", 'Im': "I'm", 'Ive': "I've",
    'isnt': "isn't", 'itd': "it'd", "itd've": "it'd've", "it'dve": "it'd've",
    'itll': "it'll", "let's": "let's", 'maam': "ma'am", 'mightnt': "mightn't",
    "mightnt've": "mightn't've", "mightn'tve": "mightn't've", 'mightve': "might've",
    'mustnt': "mustn't", 'mustve': "must've", 'neednt': "needn't",
    'notve': "not've", 'oclock': "o'clock", 'oughtnt': "oughtn't",
    "ow's'at": "'ow's'at", "'ows'at": "'ow's'at", "'ow'sat": "'ow's'at",
    'shant': "shan't", "shed've": "she'd've", "she'dve": "she'd've",
    "she's": "she's", 'shouldve': "should've", 'shouldnt': "shouldn't",
    "shouldnt've": "shouldn't've", "shouldn'tve": "shouldn't've",
    "somebody'd": 'somebodyd', "somebodyd've": "somebody'd've",
    "somebody'dve": "somebody'd've", 'somebodyll': "somebody'll",
    'somebodys': "somebody's", 'someoned': "someone'd",
    "someoned've": "someone'd've", "someone'dve": "someone'd've",
    'someonell': "someone'll", 'someones': "someone's",
    'somethingd': "something'd", "somethingd've": "something'd've",
    "something'dve": "something'd've", 'somethingll': "something'll",
    'thats': "that's", 'thered': "there'd", "thered've": "there'd've",
    "there'dve": "there'd've", 'therere': "there're", 'theres': "there's",
    'theyd': "they'd", "theyd've": "they'd've", "they'dve": "they'd've",
    'theyll': "they'll", 'theyre': "they're", 'theyve': "they've",
    'twas': "'twas", 'wasnt': "wasn't", "wed've": "we'd've",
    "we'dve": "we'd've", 'weve': "we've", 'werent': "weren't",
    'whatll': "what'll", 'whatre': "what're", 'whats': "what's",
    'whatve': "what've", 'whens': "when's", 'whered': "where'd",
    'wheres': "where's", 'whereve': "where've", 'whod': "who'd",
    "whod've": "who'd've", "who'dve": "who'd've", 'wholl': "who'll",
    'whos': "who's", 'whove': "who've", 'whyll': "why'll",
    'whyre': "why're", 'whys': "why's", 'wont': "won't",
    'wouldve': "would've", 'wouldnt': "wouldn't",
    "wouldnt've": "wouldn't've", "wouldn'tve": "wouldn't've",
    'yall': "y'all", "yall'll": "y'all'll", "y'allll": "y'all'll",
    "yall'd've": "y'all'd've", "y'alld've": "y'all'd've",
    "y'all'dve": "y'all'd've", 'youd': "you'd", "youd've": "you'd've",
    "you'dve": "you'd've", 'youll': "you'll", 'youre': "you're",
    'youve': "you've"
}

def _process_digit_article(in_text: str) -> str:
    """ìˆ«ìì™€ ê´€ì‚¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    out_text = []
    temp_text = in_text.lower().split()
    articles = ['a', 'an', 'the']
    for word in temp_text:
        word = MANUAL_MAP.setdefault(word, word)
        if word not in articles:
            out_text.append(word)
    for word_id, word in enumerate(out_text):
        if word in CONTRACTIONS:
            out_text[word_id] = CONTRACTIONS[word]
    return ' '.join(out_text)

def process_punctuation(in_text: str) -> str:
    """êµ¬ë‘ì ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. VQA/DocVQA ì‘ì—…ì—ì„œ ì¼ë°˜ì ì¸ ë°©ì‹ì…ë‹ˆë‹¤.
    ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³ , êµ¬ë‘ì ì„ ê³µë°±ìœ¼ë¡œ ë°”ê¾¼ í›„, ê³µë°±ì„ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    text = in_text.lower()
    for punc_char in string.punctuation:
        text = text.replace(punc_char, ' ')
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def process_answer_for_anls(answer: str) -> str:
    """ANLS ê³„ì‚°ì„ ìœ„í•´ ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if answer is None:
        return ""
    answer = str(answer) # ë¬¸ìì—´ì¸ì§€ í™•ì¸
    answer = answer.replace('\n', ' ')
    answer = answer.replace('\t', ' ')
    answer = answer.strip()
    answer = process_punctuation(answer)
    answer = _process_digit_article(answer)
    # anls_compute í•¨ìˆ˜ ìì²´ì—ì„œ ìµœì¢…ì ìœ¼ë¡œ lower() ë° strip()ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    return answer

def levenshtein_distance(s1: str, s2: str) -> int:
    """ë‘ ë¬¸ìì—´ ê°„ì˜ ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if len(s1) > len(s2):
        s1, s2 = s2, s1

    distances = range(len(s1) + 1)
    for i2, c2 in enumerate(s2):
        distances_ = [i2 + 1]
        for i1, c1 in enumerate(s1):
            if c1 == c2:
                distances_.append(distances[i1])
            else:
                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))
        distances = distances_
    return distances[-1]


def anls_compute(groundtruth: str, prediction: str) -> float:
    """ì •ê·œí™”ëœ ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬(ANLSì˜ ê¸°ë°˜)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    gt_answer = ' '.join(groundtruth.strip().lower().split())
    det_answer = ' '.join(prediction.strip().lower().split())
    dist = levenshtein_distance(gt_answer, det_answer)
    length = max(len(gt_answer), len(det_answer)) # (ì´ì „ì—ëŠ” groundtruth.upper() ì‚¬ìš©)ì—ì„œ ìˆ˜ì •ë¨
    if length == 0: # ë‘ ë¬¸ìì—´ ëª¨ë‘ ë¹„ì–´ìˆëŠ” ê²½ìš°
        return 0.0 if dist == 0 else 1.0 # distë„ 0ì´ë©´ ì™„ë²½ ì¼ì¹˜, ì•„ë‹ˆë©´ ë¶ˆì¼ì¹˜
    return float(dist) / float(length)

# --- regex_evaluate.pyì˜ ê¸°ì¡´ í•¨ìˆ˜ (í•„ìš”ì‹œ ìˆ˜ì •) ---

def extract_answer_from_response(response: str) -> str:
    """
    'The answer is : ~~~' í˜•íƒœì—ì„œ ë‹µë³€ ë¶€ë¶„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ "the answer is" íŒ¨í„´ ì°¾ê¸°
    pattern = r'the answer is\s*:?\s*(.+?)(?:\n|$)'
    match = re.search(pattern, response.lower())
    
    if match:
        answer = match.group(1).strip()
        return answer
    
    # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì˜ ì²« ë²ˆì§¸ ì¤„ ë°˜í™˜
    return response.split('\n')[0].strip()

def is_correct_with_anls(predicted: str, ground_truths: list, anls_threshold: float = 0.5) -> tuple[bool, float]:
    """
    ANLS ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ ë‹µë³€ì´ ì •ë‹µì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    ì–´ë–¤ ì •ë‹µ(ground truth)ì— ëŒ€í•´ì„œë“  ANLS ì ìˆ˜ê°€ anls_threshold ì´í•˜ì´ë©´ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
    ë°˜í™˜ê°’: (ì •ë‹µ ì—¬ë¶€, ìµœì  ANLS ì ìˆ˜) íŠœí”Œ
    """
    processed_predicted = process_answer_for_anls(predicted)
    if not ground_truths: # ë¹„êµí•  ì •ë‹µì´ ì—†ëŠ” ê²½ìš°
        return False, 1.0 # ì˜¤ë‹µ, ìµœëŒ€ ANLS ì ìˆ˜

    min_anls_score = float('inf')
    
    for gt in ground_truths:
        processed_gt = process_answer_for_anls(gt)
        if not processed_gt and not processed_predicted: # ì²˜ë¦¬ í›„ ë‘˜ ë‹¤ ë¹„ì–´ìˆëŠ” ê²½ìš°
             current_anls = 0.0
        elif not processed_gt or not processed_predicted: # í•˜ë‚˜ëŠ” ë¹„ì–´ìˆê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì•„ë‹Œ ê²½ìš°
            current_anls = 1.0 # í•˜ë‚˜ëŠ” ë¹„ì–´ìˆê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ìµœëŒ€ ê±°ë¦¬ (ë‘˜ ë‹¤ ë¹„ì–´ìˆì§€ ì•Šì€ í•œ)
        else:
            current_anls = anls_compute(processed_gt, processed_predicted)
        
        if current_anls < min_anls_score:
            min_anls_score = current_anls
            
    return min_anls_score <= anls_threshold, min_anls_score

def evaluate_docvqa(results_file: str, model_name: str = "SmolVLM", anls_threshold: float = 0.5):
    """
    ANLSë¥¼ ì‚¬ìš©í•˜ì—¬ DocVQA ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    """
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ê²°ê³¼ íŒŒì¼ '{results_file}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except json.JSONDecodeError:
        print(f"ì˜¤ë¥˜: '{results_file}'ì—ì„œ JSONì„ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    total = 0
    correct = 0
    
    print(f"=== DocVQA ANLS í‰ê°€ ê²°ê³¼ (ì„ê³„ê°’: {anls_threshold}) ===\n") # ìˆ˜ì •ë¨
    
    for item in results:
        if model_name not in item.get("model_response", {}):
            continue
            
        total += 1
        
        question_id = item["question_id"]
        question = item["question"]
        ground_truths = item["answers"]
        model_response_full = item["model_response"][model_name]["response"]
        
        predicted_raw = extract_answer_from_response(model_response_full)
        
        is_correct, best_anls = is_correct_with_anls(predicted_raw, ground_truths, anls_threshold) # ìˆ˜ì •ë¨
        
        if is_correct:
            correct += 1
        #else:
            # ì˜¤ë‹µ ìƒì„¸ ì •ë³´ ì¶œë ¥
            # print(f"âŒ ID: {question_id}")
            # print(f"   ì§ˆë¬¸: {question}")
            # print(f"   ì •ë‹µ(Ground Truths): {ground_truths}")
            # print(f"   ì˜ˆì¸¡(Raw): '{predicted_raw}'")
            # print(f"   ì˜ˆì¸¡(ì²˜ë¦¬ í›„): '{process_answer_for_anls(predicted_raw)}'")
            # print(f"   ìµœì  ANLS ì ìˆ˜: {best_anls:.4f} (ì„ê³„ê°’: {anls_threshold})") # ìˆ˜ì •ë¨
            # print(f"   ì „ì²´ ì‘ë‹µ: {model_response_full[:100]}...")
            # print()
            
    if total > 0:
        accuracy = correct / total
    else:
        accuracy = 0
        
    print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
    print(f"   ì´ ì§ˆë¬¸ ìˆ˜: {total}")
    print(f"   ì •ë‹µ ìˆ˜ (ANLS <= {anls_threshold}): {correct}") 
    print(f"   ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    return {
        "total": total,
        "correct": correct,
        "accuracy": accuracy,
        "anls_threshold": anls_threshold
    }

if __name__ == "__main__":
    results_file = "results/docvqa_results.json"  
    model_name_to_eval = "SmolVLM"  
    anls_eval_threshold = 0.5 # DocVQAì— ëŒ€í•œ í‘œì¤€ ANLS ì„ê³„ê°’
    
    print(f"ëª¨ë¸ í‰ê°€ ì‹œì‘: {model_name_to_eval}, ANLS ì„ê³„ê°’: {anls_eval_threshold}")
    evaluation_metrics = evaluate_docvqa(results_file, model_name_to_eval, anls_eval_threshold)
    
    if evaluation_metrics:
        print("\ní‰ê°€ ì™„ë£Œ.")
        print(f"ì „ì²´ ì •í™•ë„ ({evaluation_metrics['anls_threshold']}): {evaluation_metrics['accuracy']:.4f}")